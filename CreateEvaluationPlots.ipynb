{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d432c5-7e00-405a-8636-902be32e502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb58cb2-88fa-445c-b468-4cce04252d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"text.usetex\": True,\n",
    "    \"pgf.rcfonts\": False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c522da-8829-46ee-83d3-709c076b7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0d4b2-71e4-4e08-9201-6f2a70c99368",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregate triplets of experiments, then generate plots\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "- Use WandB API to get the list of runs from a sweep\n",
    "- Use the names of the runs to get the folder on the disk\n",
    "- Extract the config and data for each run from the disk\n",
    "- Group the triplets, then create the _average metrics by taking the mean\n",
    "\n",
    "### Generate plots\n",
    "\n",
    "- Specify the config value which shall be grouped (e.g. brain.type)\n",
    "- Specify the metric that shall be used for that plot\n",
    "- Use the prepared data, group by the specified value\n",
    "- Take the mean, and stddev for each group\n",
    "- Plot the mean as a line plot, and the stddev as a shaded region\n",
    "- X axis always \"Generation\"\n",
    "- Y axis the metric\n",
    "    - Maybe add a paramter y_axis_label because the metric might be named differently in the data compared to what we want to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af318460-bbb9-4d54-bed3-a33c7bd3795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735b216-7a5c-41b9-a34a-d06748f998f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = \"oh6v8v81\"\n",
    "\n",
    "sweep_runs = api.sweep(f\"neuroevolution-fzi/AST2023/{sweep_id}\").runs\n",
    "folder_paths = [os.path.join(\"results\", x.name.split(\"/\")[-1]) for x in sweep_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38316e-b0cd-44b7-9e68-d9270b5c81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "data_length = None\n",
    "\n",
    "for folder in folder_paths:\n",
    "    df = pd.read_json(os.path.join(folder, \"Log.json\"))\n",
    "    df = df.drop(df.index[-1], axis=0).drop(columns=[\"elapsed_time_training\", \"cpu\"])\n",
    "    \n",
    "    if data_length is not None:\n",
    "        assert len(df) == data_length\n",
    "    else:\n",
    "        data_length = len(df)\n",
    "        \n",
    "    with open(os.path.join(folder, \"Configuration.json\"), \"r\") as f:\n",
    "        cfg = json.load(f) \n",
    "    \n",
    "    raw_data.append((cfg, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094cd5f-973e-477e-b117-a485b62934e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_processed_indices = []\n",
    "grouped_triplets = {}\n",
    "\n",
    "for i, (cfg, df) in enumerate(raw_data):\n",
    "    temp_cfg = deepcopy(cfg)\n",
    "    del temp_cfg[\"global_seed\"]\n",
    "    \n",
    "    if i in already_processed_indices:\n",
    "        continue\n",
    "    \n",
    "    grouped_triplets[i] = [(cfg, df)]\n",
    "        \n",
    "    for j, (inner_cfg, inner_df) in enumerate(raw_data):\n",
    "        if i == j:\n",
    "            continue\n",
    "            \n",
    "        inner_tmp_cfg = deepcopy(inner_cfg)\n",
    "        del inner_tmp_cfg[\"global_seed\"]\n",
    "        \n",
    "        if temp_cfg == inner_tmp_cfg:\n",
    "            grouped_triplets[i].append((inner_cfg, inner_df))\n",
    "            already_processed_indices.append(j)\n",
    "            \n",
    "    already_processed_indices.append(i)\n",
    "\n",
    "assert len(grouped_triplets) == len(folder_paths) / 3\n",
    "\n",
    "prepared_data = []\n",
    "\n",
    "for triplet in grouped_triplets.values():\n",
    "    assert len(triplet) == 3\n",
    "    \n",
    "    triplet_cfg = deepcopy(triplet[0][0])\n",
    "    del triplet_cfg[\"global_seed\"]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (cfg, df) in triplet:\n",
    "        del cfg[\"global_seed\"]\n",
    "        assert triplet_cfg == cfg\n",
    "        \n",
    "        data.append(df)\n",
    "        \n",
    "    grouped_data = pd.concat(data).groupby(level=0)\n",
    "    mean_data = grouped_data.mean().rename(columns=lambda x: f\"{x}_averaged\")\n",
    "    std_data = grouped_data.std().rename(columns=lambda x: f\"{x}_std\")\n",
    "    \n",
    "    prepared_data.append((triplet_cfg, pd.concat([mean_data, std_data], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a272d-8fcf-4139-bc00-7f6032052700",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = \"brain.type\"\n",
    "grouped_data = {}\n",
    "\n",
    "for cfg, data in prepared_data:\n",
    "    group_by_splitted = group_by.split(\".\")\n",
    "    current_cfg = cfg\n",
    "    \n",
    "    for cfg_index in group_by_splitted:\n",
    "        current_cfg = current_cfg[cfg_index]\n",
    "        \n",
    "    assert not isinstance(current_cfg, dict)\n",
    "    \n",
    "    if current_cfg not in grouped_data:\n",
    "        grouped_data[current_cfg] = [data]\n",
    "    else:\n",
    "        grouped_data[current_cfg].append(data)\n",
    "        \n",
    "grouped_data_averaged = {}\n",
    "\n",
    "for cfg_key, data_list in grouped_data.items():\n",
    "    grouped = pd.concat(data_list).groupby(level=0)\n",
    "    \n",
    "    grouped_data_averaged[cfg_key] = {\n",
    "        \"mean\": grouped.mean(),\n",
    "        \"std\": grouped.std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3f042-8067-47d3-ba86-ea81677da001",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_mapper = {\n",
    "    \"mean_train_averaged\": \"mean_rew_averaged\",\n",
    "    \"best_averaged\": \"best_averaged\"\n",
    "\n",
    "}\n",
    "\n",
    "metric_to_plot = \"mean_train_averaged\"\n",
    "y_label = y_label_mapper[metric_to_plot]\n",
    "x_label = \"Generation\"\n",
    "alpha = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 4))\n",
    "\n",
    "for cfg_key, data in grouped_data_averaged.items():\n",
    "    mean_data = data[\"mean\"]\n",
    "    std_data = data[\"std\"]\n",
    "    \n",
    "    metric_data = mean_data[metric_to_plot]\n",
    "    \n",
    "    ax.plot(metric_data, label=cfg_key)\n",
    "    ax.fill_between(mean_data[\"gen_averaged\"],\n",
    "                    metric_data - std_data[metric_to_plot],\n",
    "                    metric_data + std_data[metric_to_plot], alpha=alpha)\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend(loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
